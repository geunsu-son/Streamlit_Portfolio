from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.document_loaders import UnstructuredFileLoader
from langchain.embeddings import CacheBackedEmbeddings, OpenAIEmbeddings
from langchain.schema.runnable import RunnableLambda, RunnablePassthrough
from langchain.storage import LocalFileStore
from langchain.vectorstores.faiss import FAISS
from langchain.chat_models import ChatOpenAI
from langchain.callbacks.base import BaseCallbackHandler
from langchain.memory import ConversationSummaryBufferMemory
import streamlit as st

st.set_page_config(
    page_title="SUPER-SON Resume",
    page_icon="ğŸ“„",
    layout="wide",
    initial_sidebar_state="expanded",
    menu_items={
        'Get Help': 'https://www.extremelycoolapp.com/help',
        'Report a bug': "https://www.extremelycoolapp.com/bug",
        'About': "# This is a header. This is an *extremely* cool app!"
    }
)

## --- Chatbot Code --- ##
class ChatCallbackHandler(BaseCallbackHandler):
    message = ""

    def on_llm_start(self, *args, **kwargs):
        self.message_box = st.empty()

    def on_llm_end(self, *args, **kwargs):
        save_message(self.message, "ai")

    def on_llm_new_token(self, token, *args, **kwargs):
        self.message += token
        self.message_box.markdown(self.message)

llm = ChatOpenAI(
        temperature=0.1,
        streaming=True,
        callbacks=[ChatCallbackHandler()],
    )

llm_for_memory = ChatOpenAI(
        temperature=0.1,
        streaming=True,
    )

@st.cache_data()
def load_vectorstore_and_get_retriever():
    # Load the embeddings
    embeddings = OpenAIEmbeddings()

    # Load the vectorstore from disk
    vectorstore = FAISS.load_local(f"./.cache/faiss", embeddings, allow_dangerous_deserialization=True)
    retriever = vectorstore.as_retriever()
    return retriever

def save_message(message, role):
    st.session_state["messages"].append({"message": message, "role": role})

def send_message(message, role, save=True):
    with st.sidebar:
        with st.chat_message(role):
            st.markdown(message)
    if save:
        save_message(message, role)

@st.experimental_dialog("Chat History", width = "large")
def paint_history():
    for message in st.session_state["messages"]:
        with st.chat_message(message["role"]):
            st.markdown(message["message"])

def format_docs(docs):
    return "\n\n".join(document.page_content for document in docs)

def save_memory(input, output):
    st.session_state["memory"].save_context({"input": input}, {"output": output})

def load_memory(_):
    return memory_tmp.load_memory_variables({})["history"]

prompt = ChatPromptTemplate.from_messages(
    [
        (
            "system",
            """
            ë°˜ë“œì‹œ ì£¼ì–´ì§„ 'ì´ë ¥ì„œ'ë¥¼ ì‚¬ìš©í•´ ë‹µí•˜ì„¸ìš”. ë§Œì•½ ë‹µì„ ëª¨ë¥¸ë‹¤ë©´, ê·¸ëƒ¥ ëª¨ë¥¸ë‹¤ê³  ë‹µí•˜ì„¸ìš”. ë‹¤ë¥¸ ë‹µì„ ë§Œë“¤ì§€ ë§ˆì„¸ìš”.
            
            
            ì´ë ¥ì„œ: {context}
            """,
        ),
        MessagesPlaceholder(variable_name="history"),
        ("human", "{question}"),
    ]
)

if "messages" not in st.session_state:
    st.session_state["messages"] = []

if "memory" not in st.session_state:
    st.session_state["memory"] = ConversationSummaryBufferMemory(
        llm=llm_for_memory,
        max_token_limit=500,
        return_messages=True,
    )

retriever = load_vectorstore_and_get_retriever()

## --- sidebar --- ##
with st.sidebar:
    st.page_link("home.py", label = "ì´ë ¥ì„œ", icon = "ğŸ“„")
    st.page_link("https://super-son.tistory.com", label = "í¬íŠ¸í´ë¦¬ì˜¤", icon = "ğŸ“")
    st.page_link("https://super-son.tistory.com", label = "ì‚¬ì´ë“œí”„ë¡œì íŠ¸", icon = "ğŸ’¡")
    st.divider()
    s_col1, s_col2 = st.columns([0.6, 0.4])
    with s_col1:
        st.markdown("# ğŸ¤– Chatbot")
    with s_col2:
        st.write("")
        if st.button('Chat History', use_container_width=True):
            if st.session_state["messages"] == []:
                st.sidebar.error('ì±„íŒ…í•œ ì´ë ¥ì´ ì—†ìŠµë‹ˆë‹¤. ì±„íŒ… í›„ ë‹¤ì‹œ ëˆŒëŸ¬ì£¼ì„¸ìš”.', icon='ğŸ˜ƒ')
            else:
                paint_history()

    message = st.chat_input("Ask anything about Resume...")

    if message:
        send_message(message, "human")
        memory_tmp = st.session_state["memory"]
        chain = (
            {
                "context": retriever | RunnableLambda(format_docs),
                "question": RunnablePassthrough(),
                "history": RunnableLambda(load_memory),
            }
            | prompt
            | llm
        )
        with st.chat_message("ai"):
            response = chain.invoke(message)
            save_memory(message, response.content)
                

## --- main page --- ##
col1, col2 = st.columns([0.2, 0.8],gap="medium")

with col1:
    st.image('./source/profile_photo_comic.png', use_column_width=True)
    st.write(' ')
    with st.container(border=True):
        st.markdown("##### :hammer_and_wrench: Skill.")
        skill_dict = {'Python':0.9,
                      'SQL':0.7,
                      'AI':0.4,
                      'Excel':1.0,
                      'PowerPoint':0.9}
        
        for skill_name, skill_stat in skill_dict.items():
            st.progress(skill_stat, skill_name)

    with st.container(border=True):
        st.write(
        """
        ##### Contact.
        ğŸ“ Tel. 010-4430-2279  
        ğŸ“© E-mail. [gnsu0705@gmail.com](gnsu0705@gmail.com)  
        ğŸ’» Blog. [Super-Son](https://super-son.tistory.com/)
        """
        )
with col2:
    st.write(
        """
### ì†ê·¼ìˆ˜ &mdash; ë°ì´í„° ë¶„ì„ê°€  
ë°©ë¬¸í•´ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤. ğŸ‘‹  
ì €ëŠ” :orange[ì œê°€ ê°€ì§„ ëŠ¥ë ¥ìœ¼ë¡œ ë‹¤ë¥¸ ì‚¬ëŒë“¤ì„ ë•ëŠ” ê²ƒì— ê¸°ì¨ì„ ëŠë¼ëŠ” ë°ì´í„° ë¶„ì„ê°€]ì…ë‹ˆë‹¤.  
ì €ë¥¼ ë” ì•Œë¦¬ê³  ì¢‹ì€ ì‚¬ëŒë“¤ê³¼ ì¼í•˜ê³  ì‹¶ì–´ ì´ ì‚¬ì´íŠ¸ë¥¼ ë§Œë“¤ê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤.  

í•˜ë‹¨ì˜ ë‚´ìš©ì„ í†µí•´ ì œ ì´ë ¥ì„ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìœ¼ë©°,  
ğŸ‘ˆ ì‚¬ì´ë“œë°”ì˜ :blue[ì±—ë´‡]ì„ í™œìš©í•˜ë©´ ë” ìì„¸í•œ ë‚´ìš©ì„ ì•Œì•„ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ğŸ˜ƒ

    """
    )
    st.write(' ')
    
    tab1, tab2 = st.tabs(["ê²½ë ¥", "í•™ë ¥ ë° ìê²©ì¦"])

    with tab1:
        st.write(
            """
    #### ë°ì´í„° ë¶„ì„ê°€ | í¼í”Œì•„ì¹´ë°ë¯¸
    **ì „ëµì‚¬ì—…ë¶€ ê³¼ì¥/íŒŒíŠ¸ì¥**  
    2020.04 ~ 2024.03 (48ê°œì›”)  

    - í•™ìŠµë°ì´í„° í¬ë¡¤ë§  
        ì‚¬ìš©ì¤‘ì¸ ì™¸ë¶€ 5ê°œ í•™ìŠµ ì‚¬ì´íŠ¸ì˜ ë°ì´í„°ë¥¼ ì •ê¸°ì ìœ¼ë¡œ í¬ë¡¤ë§í•  ìˆ˜ ìˆë„ë¡ êµ¬ì¶•  
        
    - ë°ì´í„° ë¶„ì„  
        ë‚´ë¶€ ë°ì´í„°ë¥¼ í™œìš©í•œ ì˜ì‚¬ê²°ì •ì— í•„ìš”í•œ ë°ì´í„° ë¶„ì„ ê²°ê³¼ ë„ì¶œ  
        
    - ì‹ ê·œ ì„œë¹„ìŠ¤ ê¸°íš ë° ì œì‘ ì°¸ì—¬  
        1) í•™ìŠµ í‰ê°€ ëª¨ë¸  
            í•™ìƒë“¤ì˜ í•™ìŠµ ê²°ê³¼ë¥¼ ê¸°ë°˜ ê° í•™ë…„ë³„ í•™ìŠµ í‰ê°€ ëª¨ë¸ êµ¬ì¶•  
        
        2) ì¶”ì²œë„ì„œ  
            í•™ìƒë“¤ì˜ ë¦¬ë”© ë°ì´í„° ë° ì‚¬ë‚´ í•™ìŠµ ê°€ì´ë“œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë§ì¶¤í˜• ë„ì„œ ì¶”ì²œ ì„œë¹„ìŠ¤ ì œì‘  
        
    - í”„ë¡œì íŠ¸ ë§¤ë‹ˆì§•  
        1) í™ˆí˜ì´ì§€ ë¦¬ë‰´ì–¼  
            2021ë…„ 1ì›” ì‹ ê·œ í™ˆí˜ì´ì§€ ëŸ°ì¹­ ì›¹ê¸°íš ë° ì¼ì • ê´€ë¦¬  

        2) ì‹ ê·œ ì„œë¹„ìŠ¤ ëŸ°ì¹­ PM  
            2024ë…„ 2ì›” ì‹ ê·œ ëŸ°ì¹­ ì„œë¹„ìŠ¤ ì¼ì • ê´€ë¦¬ ë° ì„œë¹„ìŠ¤ í’ˆì§ˆ ê´€ë¦¬  
    """
            )

        with tab2:
            st.write("""
    **í†µê³„í•™ê³¼ | ìˆ­ì‹¤ëŒ€í•™êµ**  
    2012.02. - 2018.09.

    **ADsP (ë°ì´í„°ë¶„ì„ ì¤€ì „ë¬¸ê°€)  | í•œêµ­ë°ì´í„°ì‚°ì—…ì§„í¥ì›**  
    2018.12
    """
            )
